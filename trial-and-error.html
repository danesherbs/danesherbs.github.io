<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Trial and Error</title>
  <link href="style.css" rel="stylesheet" />
</head>

<body>

  <table>
    <tr>
      <td>
        <header>
          Trial and Error
        </header>
        </br>
        September 2020
        </br>
        </br>
        How likely is it that a solution to a problem is optimal? Unless it's a well-behaved mathematical problem, it's
        stupefyingly improbable [1]. How likely is it that it's the most impactful problem that could be solved right
        now? Unless the opportunity cost of solving other problems has been carefully considered, it's also
        improbable.

        </br>
        </br>

        We're therefore continually trying out new ideas and error correcting -- on our solution, and on the problem
        itself. Surprisingly, a lot of good advice amounts to one thing: speeding up the trial and error loop.

        <img src="trial-and-error.jpeg" style="width: 12em;" class="center" alt="trial-and-error">

        When writing software, it's best to build the simplest end-to-end system as fast as possible. This
        leads you to ask the right questions earlier, like "do we really want to solve X, or do we actually want to
        solve Y?", "do we have the right expertise to solve problem Y?" and "how do we even measure our progress on
        problem Y?". The faster the loop, the better.

        <blockquote>
          “The question is, how fast can you discover that the thing you’re working on is the wrong thing to be working
          on.”
          <br>
          ― Astro Teller, Captain of Moonshots at X
        </blockquote>

        Maybe you've found it to be true in conversation. When you're explaning a topic, it's better to give a minute
        summary and elaborate if they're interested than to dive into detail at the outset.

        </br>
        </br>

        Or maybe you've found it to be true if you've written software. How much easier is it to write
        software with a REPL than without? What about when your program takes minutes to compile? It can be
        really frustrating when you're in a slow loop.

        <!-- </br>
        </br> -->

        <!-- Feedback loops only work if you have the correct signal, though. You can't improve your solution if you can't
        find out what's wrong with it. Paul Graham often advises start ups to talk to users -- this is the signal that
        start ups should be paying attention to and error correcting on. -->

        <!-- Elon Musk put engineers right by the Tesla assembly line. If any of their solutions failed, the error signal
        wasn't diluted by being passed through a chain of command -- they could go inspect the error themselves. -->

        <!-- There's a number of suprising places this principle arises. Paul Graham advises start ups to release early
        to quickly discover any major flaws, like a poor business idea or problems among founders. Neural networks first
        start with random parameters, but the error in their predictions is measured and parameters are iteratively
        updated via backpropagation. Likewise, solutions to intractable PDEs are approximated with iterative schemes
        like Gauss-Seidel and Lax Wendroff. -->

        </br>
        </br>

        Part of reaching a good solution is not getting discouraged after failing over and over. Paul Graham has often
        said the best predictor of start up success is how determined the founders are [2]. Carol Dweck's point on
        growth mindset is essentially making the point that everyone's first iterations look bad. The greats are those
        that just did lots of cycles.

        <!-- </br>
        </br> -->

        <!-- It's also common in numerical analysis. The idea is to try a solution, measure the error, and try a better
        solution in the next iteration. Iterative schemes for solving PDEs, like Guass-Seidel and Lax Wendroff, follow
        this pattern. As does training neural networks: initially the parameters are random, but the error is measured
        and parameters are updated using back-propagation. -->

        <!-- Numerical analysis - absence of an analytic solution - try a solution, measure error, try a better solution next
        time. Iterative schemes for solving PDEs e.g. Gauss-Seidel, Lax Wendroff. Training neural networks - guess
        parameters, error correct using back-propagation. Expectation Maximisation algorithm e.g. Gaussian mixture
        models. -->

        <!-- </br>
        </br>

        What about when applying for positions? We may delay applying out of fear of rejection, but in reality we'd be
        far better off applying. If we do fail, we'll have a much more accurate picture in how to succeed next time. It
        could inform future projects or interview preparation techniques.

        </br>
        </br>


        Paul Graham's advice to release early is the same sentiment. "Release early" is common start up advice from Paul
        Graham and Reid Hoffman. Paul Graham PG's "talk to
        users" is telling you which signal to pay attention to. PG's "release early" is
        shortening the
        feedback loop. PG's "determination is more important than intelligence" is saying it's more important to execute
        the loop many times than to reduce the work done per step.

        </br>
        </br>

        Trial and error is also central to many good ideas, namely science and democracy. In science, candidate theories
        a chosen, experiments are performed and theories are error-corrected. In
        democracy, the best candidate is voted into power, their policy executed, and we error-correct by not voting in
        cadidates that repeat previous mistakes. This only works when not only the candidate is replaced, but their
        policies also.

        </br>
        </br>

        Determination, keep executing the loop, more cycles almost always beats more work done per cycle
        </br>
        <ul>
          <li>Speed is time/step.</li>
          <li>Intelligence is work done/step i.e. how good error correction is.</li>
          <li>Determination is keep executing the loop. It's more important to keep executing the loop than to increase
            work done per step.</li>
          <li>Not getting discouraged while iterating the loop</li>
          <li>Whenever you can find a feedback loop you can be successful</li>
        </ul>

        </br>
        </br>

        <ul>
          <li>Science - hypothesis, experiment, correct theory</li>
          <li>Democracy - David Deutsch - pick best candidate, error correct. Peaceful transition of power is key to the
            loop continuing to execute.</li>
          <li>Start ups - Paul Graham - talk to users (signal you should pay attention to), be determined (keep
            executing)</li>
          <li>Engineering - Google X - fail fast - “The question is,” said Dr. Astro Teller, “how fast can you
            discover that the thing you’re working on is the wrong thing to be working on.”</li>
          <li>Growth Mindset - Carol Dweck - everyones first iterations of the loop look bad - experts are those that
            just kept executing the loop</li>
          <li>Elon Musk - Tesla - optimise for tighter feedback-loop between assembly line and engineers</li>
          <li>Job applications - applying and failing, then gaining relevant experience, as opposed to preparing for
            ages in isolation and realising that you should have been doing something completely different</li>
          <li>Programming - easier to program with a REPL</li>
          <li>Project management - build the simplest end-to-end system first. This leads to you asking the right
            questions earlier, like "do we really want to solve X, or do we actually want to solve Y?" and "how do we
            even measure our progress on problem Y?"</li>
          <li>Numerical analysis - absence of an analytic solution - try a solution, measure error, try a better
            solution next time. Iterative schemes for solving PDEs e.g. Gauss-Seidel, Lax Wendroff. Training neural
            networks - guess parameters, error correct using back-propagation. Expectation Maximisation algorithm e.g.
            Gaussian mixture models.</li>
          <li>Explaning a topic. Better to give a minute summary and go into more detail if necessary than dive into
            detail at the outset. The tighter the feedback loop the better.</li>
          <li>GPUs speeding up experiemnts in ML</li>
        </ul>

        </br>
        </br>

        A lot of good advice boils down to having a tighter trial and error loop (e.g. Google X "fail fast",
        PG's "release early"), or to keep executing it (e.g. Carol Dweck's Growth Mindset, PG's "determination matters
        more than intelligence"). -->

        </br>
        </br>

        Have a fast trial and error loop, and don't give up.

        </br>
        </br>

        <b>Footnotes</b>
        </br>
        [1] Sometimes mathematics allows for analytic solutions. This is
        quite rare, though. For example, there's an analytic solution for the parameters in linear regression (the
        normal equations), but as soon as you add a non-linear activation function (e.g. the
        logistic function), there's no longer an anlytic solution. Instead, numerical methods are used (e.g. gradient
        descent), which uses trial and error to find successively better parameters.
        </br>
        [2] <a href="http://www.paulgraham.com/determination.html">http://www.paulgraham.com/determination.html</a>


      </td>
    </tr>
  </table>

</body>

</html>